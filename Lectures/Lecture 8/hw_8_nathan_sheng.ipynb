{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06005876-10c4-4e8a-b0a3-13567e542247",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_location = 'sqlite:///../../data/data.db'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8946a39-da27-4d82-a8a2-4fdad384b9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import reduce\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90d62530-424e-4470-9d3d-9ed0342e5be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vol_ohlc(df, lookback=10):\n",
    "    o = df.open\n",
    "    h = df.high\n",
    "    l = df.low\n",
    "    c = df.close\n",
    "    \n",
    "    k = 0.34 / (1.34 + (lookback+1)/(lookback-1))\n",
    "    cc = np.log(c/c.shift(1))\n",
    "    ho = np.log(h/o)\n",
    "    lo = np.log(l/o)\n",
    "    co = np.log(c/o)\n",
    "    oc = np.log(o/c.shift(1))\n",
    "    oc_sq = oc**2\n",
    "    cc_sq = cc**2\n",
    "    rs = ho*(ho-co)+lo*(lo-co)\n",
    "    close_vol = cc_sq.rolling(lookback).sum() * (1.0 / (lookback - 1.0))\n",
    "    open_vol = oc_sq.rolling(lookback).sum() * (1.0 / (lookback - 1.0))\n",
    "    window_rs = rs.rolling(lookback).sum() * (1.0 / (lookback - 1.0))\n",
    "    result = (open_vol + k * close_vol + (1-k) * window_rs).apply(np.sqrt) * np.sqrt(252)\n",
    "    result[:lookback-1] = np.nan\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9af55f61-98fc-4eb0-a241-777a73371940",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(\n",
    "    estimator,\n",
    "    title,\n",
    "    X,\n",
    "    y,\n",
    "    axes=None,\n",
    "    ylim=None,\n",
    "    cv=None,\n",
    "    n_jobs=None,\n",
    "    train_sizes=np.linspace(0.1, 1.0, 5),\n",
    "    scoring=None\n",
    "):\n",
    "    if axes is None:\n",
    "        _, axes = plt.subplots(1, 3, figsize=(20, 5))\n",
    "\n",
    "    axes[0].set_title(title)\n",
    "    if ylim is not None:\n",
    "        axes[0].set_ylim(*ylim)\n",
    "    axes[0].set_xlabel(\"Training examples\")\n",
    "    axes[0].set_ylabel(\"Score\")\n",
    "\n",
    "    train_sizes, train_scores, test_scores, fit_times, _ = learning_curve(\n",
    "        estimator,\n",
    "        X,\n",
    "        y,\n",
    "        cv=cv,\n",
    "        n_jobs=n_jobs,\n",
    "        train_sizes=train_sizes,\n",
    "        return_times=True,\n",
    "        scoring=scoring,\n",
    "    )\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    fit_times_mean = np.mean(fit_times, axis=1)\n",
    "    fit_times_std = np.std(fit_times, axis=1)\n",
    "\n",
    "    # Plot learning curve\n",
    "    axes[0].grid()\n",
    "    axes[0].fill_between(\n",
    "        train_sizes,\n",
    "        train_scores_mean - train_scores_std,\n",
    "        train_scores_mean + train_scores_std,\n",
    "        alpha=0.1,\n",
    "        color=\"r\",\n",
    "    )\n",
    "    axes[0].fill_between(\n",
    "        train_sizes,\n",
    "        test_scores_mean - test_scores_std,\n",
    "        test_scores_mean + test_scores_std,\n",
    "        alpha=0.1,\n",
    "        color=\"g\",\n",
    "    )\n",
    "    axes[0].plot(\n",
    "        train_sizes, train_scores_mean, \"o-\", color=\"r\", label=\"Training score\"\n",
    "    )\n",
    "    axes[0].plot(\n",
    "        train_sizes, test_scores_mean, \"o-\", color=\"g\", label=\"Cross-validation score\"\n",
    "    )\n",
    "    axes[0].legend(loc=\"best\")\n",
    "\n",
    "    # Plot n_samples vs fit_times\n",
    "    axes[1].grid()\n",
    "    axes[1].plot(train_sizes, fit_times_mean, \"o-\")\n",
    "    axes[1].fill_between(\n",
    "        train_sizes,\n",
    "        fit_times_mean - fit_times_std,\n",
    "        fit_times_mean + fit_times_std,\n",
    "        alpha=0.1,\n",
    "    )\n",
    "    axes[1].set_xlabel(\"Training examples\")\n",
    "    axes[1].set_ylabel(\"fit_times\")\n",
    "    axes[1].set_title(\"Scalability of the model\")\n",
    "\n",
    "    # Plot fit_time vs score\n",
    "    fit_time_argsort = fit_times_mean.argsort()\n",
    "    fit_time_sorted = fit_times_mean[fit_time_argsort]\n",
    "    test_scores_mean_sorted = test_scores_mean[fit_time_argsort]\n",
    "    test_scores_std_sorted = test_scores_std[fit_time_argsort]\n",
    "    axes[2].grid()\n",
    "    axes[2].plot(fit_time_sorted, test_scores_mean_sorted, \"o-\")\n",
    "    axes[2].fill_between(\n",
    "        fit_time_sorted,\n",
    "        test_scores_mean_sorted - test_scores_std_sorted,\n",
    "        test_scores_mean_sorted + test_scores_std_sorted,\n",
    "        alpha=0.1,\n",
    "    )\n",
    "    axes[2].set_xlabel(\"fit_times\")\n",
    "    axes[2].set_ylabel(\"Score\")\n",
    "    axes[2].set_title(\"Performance of the model\")\n",
    "\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d02eebea-274d-4ce0-a0f3-519fcca8c48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohlc = pd.read_sql('SELECT * FROM ohlc', data_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55c40074-ad10-4948-adb5-17e0b16269df",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = ohlc.token.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d414a399-bf99-41ca-ac7d-1bc4d1931969",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_merge(left, right):\n",
    "    return pd.merge(left, right, on='ts', how='inner')\n",
    "\n",
    "X = reduce(df_merge, [\n",
    "    (lambda df: \n",
    "    (\n",
    "        df\n",
    "        .assign(\n",
    "            vol=vol_ohlc(df).fillna(0),\n",
    "            ret=df.close.pct_change()\n",
    "        )[['ts', 'vol', 'ret']]\n",
    "        .rename(columns={\n",
    "            col: f'{col}_{token}' for col in ['ts', 'vol', 'ret'] if col != 'ts'\n",
    "        })\n",
    "    ))(ohlc[ohlc.token == token])\n",
    "    for token in tokens\n",
    "]).set_index('ts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e47668a-6b8c-4da6-9d92-f9eed43b04a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = X.ret_SOL.shift(-1)[:-1]\n",
    "X = X[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4147dec4-4508-4381-ada6-ff05d221d263",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "\n",
    "from sklearn.model_selection import learning_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff1779bf-af60-4128-baaa-c19400e7b348",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X, y, test_size=0.2):\n",
    "    cv = TimeSeriesSplit(n_splits=int(y.shape[0] * test_size), test_size=1)\n",
    "    scorer = make_scorer(mean_squared_error, greater_is_better=False, squared=False)\n",
    "    \n",
    "    return np.mean(cross_validate(model, X, y, cv=cv, scoring=scorer, n_jobs=-1)['test_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e15285-d9cb-4bb6-b7c7-97149ebc0626",
   "metadata": {},
   "source": [
    "The best model found in class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0c18585f-b2fe-486f-a00c-836d56e23ff9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.008575217852018856"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('impute', SimpleImputer(missing_values=np.nan, strategy='constant', fill_value=0.)),\n",
    "    ('scale', StandardScaler()),\n",
    "    ('pca', PCA(n_components=20)),\n",
    "    ('model', Ridge(alpha=1.))\n",
    "])\n",
    "\n",
    "evaluate_model(pipeline, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1ae573-8f74-40c4-b726-1b6632c0d8c3",
   "metadata": {},
   "source": [
    "Add polynomial/interaction features, and reduce overfitting by lowering PCA to single-component:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "05467be4-3b4d-4822-83c5-c845418b5d12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.008566702391689676"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('impute', SimpleImputer(missing_values=np.nan, strategy='constant', fill_value=0.)),\n",
    "    ('scale', StandardScaler()),\n",
    "    ('polynomial', PolynomialFeatures()),\n",
    "    ('pca', PCA(n_components=1)),\n",
    "    ('model', Ridge(alpha=1.))\n",
    "])\n",
    "\n",
    "evaluate_model(pipeline, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ea0996-56e3-4e0e-81e6-c6f15c897aca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
