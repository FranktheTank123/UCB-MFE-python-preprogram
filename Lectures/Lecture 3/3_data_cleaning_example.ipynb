{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we've gone over how to visualize and clean data, let's take a look at how we would use this in real life.\n",
    "\n",
    "Our goal is to take a data set from an API, and use it for some analysis.  However, our API is a little flakey and the data sometimes isn't great, so we'll need to figure out what we need to correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import reduce\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(token):\n",
    "    res = requests.get(\n",
    "        f'https://api.cryptowat.ch/markets/coinbase-pro/{token}usd/ohlc',\n",
    "        params={\n",
    "            'periods': '3600',\n",
    "            'after': str(int(pd.Timestamp('2021-12-01').timestamp()))\n",
    "        }\n",
    "    )\n",
    "    df = pd.DataFrame(\n",
    "        res.json()['result']['3600'],\n",
    "        columns=['ts', 'open', 'high', 'low', 'close', 'volume', 'volumeUSD']\n",
    "    )\n",
    "    df['ts'] = pd.to_datetime(df.ts, unit='s')\n",
    "    df['token'] = token\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = ['BTC', 'ETH', 'USDT', 'SOL', 'ADA', 'XRP', 'DOT', 'AVAX']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [\n",
    "    (lambda x: x.assign(chain=np.where(x.token.isin(['ETH', 'AAVE', 'COMP']), np.full(x.shape[0], 'ETH'), x.token)))(get_data(token)) \n",
    "    for token in tokens\n",
    "]\n",
    "\n",
    "df = pd.concat(get_data(token) for token in tokens)\n",
    "df['chain'] = np.where(df.token.isin(['ETH', 'AAVE', 'COMP']), np.full(df.shape[0], 'ETH'), df.token)\n",
    "df.set_index('ts', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do some chaos monkeying\n",
    "df['close'] = df['close'].mask(np.random.random(df.shape[0]) < .05, other=np.nan)\n",
    "df['close'] = df['close'].mask(np.random.random(df.shape[0]) < .01, other=df['close'] * 100)\n",
    "df['token'] = df['token'].mask(np.random.random(df.shape[0]) < .05, other='<a>' + df['token'] + '</a>')\n",
    "df = df.append(df.sample(frac=0.1)).sample(frac=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's check our time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can see that we have 2264, total entries, but close has a bunch of nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['token'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we also have some badly formatted token names (maybe we pulled from html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we also have some duplicated rows it looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['token', 'close']].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this plot doens't make sense because we have a long table.  Let's plot by token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_in_df = df.token.unique()\n",
    "\n",
    "fig, axes = plt.subplots(nrows=math.ceil(tokens_in_df.size / 2), ncols=2, figsize=(15, 5 * math.ceil(tokens_in_df.size / 2)))\n",
    "\n",
    "idx = 0\n",
    "for label, df_token in df[['token', 'close']].groupby('token'):\n",
    "    df_token['close'].plot(ax=axes[idx // 2, idx % 2], label=label)\n",
    "    axes[idx // 2, idx % 2].legend()\n",
    "    \n",
    "    idx += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we definitely see some missing data from this plot, but also we definitely have some outliers in our data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "okay so what do we do?  let's get a plan of attack:\n",
    "1. Let's remove the duplicated rows\n",
    "2. Let's format the names for the tokens so we don't have the ones with tags\n",
    "3. Let's use a heuristic for missing close price as average of high + low of they day\n",
    "\n",
    "After this, we can take a look at our chart and see how we want to deal with the outliers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. drop duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. let's format the token names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['token'].str.contains('<a>'), 'token'] = df.loc[df['token'].str.contains('<a>'), 'token'].str.extract('<a>(.|\\n)*?<\\/a>')\n",
    "df_res['column_A'] = df_res['column_A'].str.extract('<b>(.|\\n)*?<\\/b>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. use the heuristic for missing close prices as verage of high + low of the day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['close'].isnull(), 'close'] = 0.5 * (df.loc[df['close'].isnull(), 'high'] + df.loc[df['close'].isnull(), 'low'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the same chart again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_in_df = df.token.unique()\n",
    "\n",
    "fig, axes = plt.subplots(nrows=math.ceil(tokens_in_df.size / 2), ncols=2, figsize=(15, 5 * math.ceil(tokens_in_df.size / 2)))\n",
    "\n",
    "idx = 0\n",
    "for label, df_token in df[['token', 'close']].groupby('token'):\n",
    "    df_token['close'].plot(ax=axes[idx // 2, idx % 2], label=label)\n",
    "    axes[idx // 2, idx % 2].legend()\n",
    "    \n",
    "    idx += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we now have good names, no duplicates and no missing values as we can see from the chart, however we still have these massive outliers.  Let's see how to deal with these.\n",
    "\n",
    "Let's come up with a heuristic to define an outlier, as something where the close price is greater than 2x higher or lower than the open price (given this is hourly data, we shouldn't expect it to change that much)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.close / df.open >= 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this heuristic looks okay - let's use the missing value heuristic to fill these in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.close / df.open >= 2, 'close'] = 0.5 * (df.loc[df.close / df.open >= 2, 'high'] + df.loc[df.close / df.open >= 2, 'low'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_in_df = df.token.unique()\n",
    "\n",
    "fig, axes = plt.subplots(nrows=math.ceil(tokens_in_df.size / 2), ncols=2, figsize=(15, 5 * math.ceil(tokens_in_df.size / 2)))\n",
    "\n",
    "idx = 0\n",
    "for label, df_token in df[['token', 'close']].groupby('token'):\n",
    "    df_token['close'].plot(ax=axes[idx // 2, idx % 2], label=label)\n",
    "    axes[idx // 2, idx % 2].legend()\n",
    "    \n",
    "    idx += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
