{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0367555b-facc-4e18-935a-331ab9738ad0",
   "metadata": {},
   "source": [
    "# Pandas DataFrames (`pd.DataFrame`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed00cbe-78dd-4a0b-96ba-053da67d9c6e",
   "metadata": {},
   "source": [
    "The pandas dataframe is the workhorse of most data science and analytics projects.  The dataframe represents the data you're working with as a table.  However, the flexibility of the dataframe is that each row **and** column is represented as a pandas Series, which allows for many powerful ways to mess around with the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5652447b-94f7-4e07-befb-9b69b08c565a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1bc867c-f37b-4981-bdac-efb604182b11",
   "metadata": {},
   "source": [
    "First let's get some data so we can see what we can do with a data frame.  Don't worry about exactly what this function is doing, we will go over it in a bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40cde993-09d8-45cc-9402-b11c1da684dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(token):\n",
    "    res = requests.get(\n",
    "        f'https://api.cryptowat.ch/markets/coinbase-pro/{token}usd/ohlc',\n",
    "        params={\n",
    "            'periods': '3600',\n",
    "            'after': str(int(pd.Timestamp('2021-12-01').timestamp()))\n",
    "        }\n",
    "    )\n",
    "\n",
    "    df = pd.DataFrame(\n",
    "        res.json()['result']['3600'],\n",
    "        columns=['ts', 'open', 'high', 'low', 'close', 'volume', 'volumeUSD']\n",
    "    )\n",
    "    df['ts'] = pd.to_datetime(df.ts, unit='s')\n",
    "    df['token'] = token\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e162a7-e4e8-4ea8-bc51-3a6ea20d712c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = ['BTC', 'ETH', 'SOL', 'AAVE', 'COMP']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b9e302-2683-40a0-93c7-6a201107b3d6",
   "metadata": {},
   "source": [
    "Don't worry too much about what is going on in the function below - we'll briefly go over it as it showcases the power of python, but it's not necessary for the class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff7e902-ea09-4d69-bccf-237218b77ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [\n",
    "    (lambda x: x.assign(chain=np.where(x.token.isin(['ETH', 'AAVE', 'COMP']), np.full(x.shape[0], 'ETH'), x.token)))(get_data(token)) \n",
    "    for token in tokens\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723cd451-3cde-4ea1-9427-7bc25f5856a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base = pd.concat(get_data(token) for token in tokens)\n",
    "df_base['chain'] = np.where(df_base.token.isin(['ETH', 'AAVE', 'COMP']), np.full(df_base.shape[0], 'ETH'), df_base.token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14adae4-6983-4338-bc97-e0727776e3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_base.set_index('ts')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d735f6f-865c-4a93-9ddf-19ea89680c4d",
   "metadata": {},
   "source": [
    "## Understanding the data frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a5da29-9225-473b-8e10-b108009f15c1",
   "metadata": {},
   "source": [
    "After loading the data in our data frame, we can now inspect what's inside.  We'll need to do this as often the data we will store will be impossible to inspect row by row, and we will need to check that our data loading was correct\n",
    "\n",
    "Let's check some basic properties of the data set:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8a4be5-5ab2-4c8f-8208-f2169b7f96d8",
   "metadata": {},
   "source": [
    "We can see how many rows and columns this data frame has, and total number of data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6438d194-14eb-4f65-abce-763331771881",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8406d76-f021-4398-a47a-ec42390fb9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e14968-4af1-4a61-9fde-22906079f5d3",
   "metadata": {},
   "source": [
    "We can see what the first 5 rows looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f018911f-5c56-4996-8c16-5f2f00bd270d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5c871e-9901-480b-8ce0-07925bff5da2",
   "metadata": {},
   "source": [
    "...and the last 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042243e1-6035-40a9-9bd3-15c8be8452c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3a5fbc-1797-4b87-ac80-9ef542d658eb",
   "metadata": {},
   "source": [
    "We can also see a general overview of the schema (column name, data and data type) of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b531c3e4-a455-45a1-bb66-f356cb35efde",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19716969-c7cf-4723-a804-1035b6e879a0",
   "metadata": {},
   "source": [
    "as well as descriptive statistics about every column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5673ee3b-1313-4525-ae2f-64927dc6890c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3988b5d-5a11-464f-a437-45fe4003f225",
   "metadata": {},
   "source": [
    "## DataFrame Indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6af5db9-da51-4722-8bb8-f38b5bc53879",
   "metadata": {},
   "source": [
    "Indexing in data frames works very similar to Series, however there are now two \"axes\" that we can operate on - rows and columns.  For example, using `[*]` for indexing (like in series) by default will operate on columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac04f25e-7fda-4712-828d-3cd20a78decd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['open']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abbeaf9-fa89-4f63-a6d5-60a9e149b6cc",
   "metadata": {},
   "source": [
    "however using `.loc[*]` will allow you to access rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9c8b63-1267-4dd5-9041-6f733811cdf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['2021-12-01 01:00:00']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69283f1e-7709-40cc-aca0-500791788a81",
   "metadata": {},
   "source": [
    "and `.iloc[*]` will get you positional rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33bdd661-5384-43a1-b647-8c3c07bd1a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2afb44-1675-4716-8013-9ba7718c563f",
   "metadata": {},
   "source": [
    "we can also get to the last row easily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57edf5af-1e90-457e-b6d4-3702765627c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52437762-fb24-4ecf-a671-3c5a9474cdc9",
   "metadata": {},
   "source": [
    "or return it as a data frame instead of a Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fef618-d272-48c9-8664-72d4e4d9b4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[[-1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a70a89-e81b-4ead-847d-652bd69d7d6a",
   "metadata": {},
   "source": [
    "**note**: `df.loc[0]` will not work, as this is accessing via index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920d280d-1acf-4103-80f2-f1306df1d2c2",
   "metadata": {},
   "source": [
    "---\n",
    "**note**: Also, the index operators will return a `pd.Series` if there's 1 row returned, or a new `pd.DataFrame` if multiple rows are returned, e.g.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53cb94f-6552-471a-a61f-fbc84383f4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9dd0a2c-4716-4254-9978-bcd71277d919",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df.loc['2021-12-01 01:00:00']) # 5 rows returned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f54e5f-6c09-4af8-bd6b-c1f9cbfcab37",
   "metadata": {},
   "source": [
    "we can convert a Series to a DataFrame anytime by using the `.to_frame()` method on the Series object.  This will turn the Series to a DataFrame, using the `Series.name` as the column name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81513a2e-3550-4720-b2ae-7a1283cf8d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[0].to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5acb8246-8246-446b-8373-971f1c0f55a4",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30c9282-f938-4698-ba12-3817822bf1e6",
   "metadata": {},
   "source": [
    "In addition, we can select on multiple columns and rows in various ways:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fecfe38-aad3-4abf-aab9-58b5ff172a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['open', 'close']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95bc4985-ed4a-4577-a239-d8aaa7753a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41901cd-ce4c-4a99-8891-7b98aaeaee5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['2021-12-01 00:00:00':'2021-12-01 02:00:00']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c6b34d-eaaa-4024-af7e-8635d6da006b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d37509-dcbf-41b8-a223-e839426692b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[[0, 4, 10, 50]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e893898a-28dd-409f-87fb-1ecb72f84eb2",
   "metadata": {},
   "source": [
    "And finally, we can index on both rows and columns at the same time with `.loc`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497a1b31-6e05-4409-872d-7c1bc3342d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['2021-12-01 00:00:00':'2021-12-01 02:00:00', ['close', 'volume', 'token']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f21592-a7b4-40bb-a868-096ee5f641f7",
   "metadata": {},
   "source": [
    "**note**: Given that by default dataframe indices are sequential integers by default, it's good practice to use `.loc` and `.iloc` to index into the data frame to be very clear, for example, let's shuffle our data frame then select:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b60601-e3c1-4957-b6d1-ef36a621f3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shuffled = df_base.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b85cf0d-da18-40c7-8b2b-c91d8b89e083",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shuffled.loc[[0, 2, 3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a082c81-99d7-45e1-8264-02f97ce95705",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shuffled.iloc[[0, 2, 3]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2007107c-8b0b-489e-98e6-e7c6cb3995f7",
   "metadata": {},
   "source": [
    "lastly, we can set the DataFrame index from a column, or remove an index into a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c62aa04-7123-4d93-84c5-a435e4860464",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shuffled.set_index('ts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f62b051-af2e-4b43-93c6-a2dda89bd620",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shuffled.set_index('ts').reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1254a22-3c7a-40ec-a534-462773f41bfd",
   "metadata": {},
   "source": [
    "## DataFrame Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f2c8be-82e2-410b-bfbd-9ae62a8b33d7",
   "metadata": {},
   "source": [
    "Filtering a data frame is very similar to filtering a series.  We can filter on any set of columns, the filtering is done via indices.  For example, if we wanted to just get the data points for tokens on the ethereum chain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e651da-18c1-4f16-82bf-1a68d6db910c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['chain'] == 'ETH'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e97149-5621-4129-ba6b-d38d897bd394",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['chain'] == 'ETH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a05b27-c119-492f-bdc5-5e0aecf6b838",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['chain'] == 'ETH', 'close']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899849d0-7bda-4aa7-be9a-e0d457a0b8fa",
   "metadata": {},
   "source": [
    "## Deleting from Dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e9f5e5-5511-4155-8a93-f4f12a605afe",
   "metadata": {},
   "source": [
    "We can select for all the things we'd like, but we can also drop both rows and columns.  This also works by index, i.e.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181d43fd-fbed-4f12-a49f-c3b4b509d491",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(pd.to_datetime('2021-12-01 00:00:00'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89497211-9e82-4f6d-8f5b-70bf5c29ba56",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns='volumeUSD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669aebdd-a149-47e9-a69e-88a6f914cb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['close', 'open'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39768d4b-b8bf-4d81-b47a-11230f227e0b",
   "metadata": {},
   "source": [
    "## Common Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba1e857-8416-4a74-a194-e6c33e3a149e",
   "metadata": {},
   "source": [
    "Like with pandas Series, a DataFrame is simply a numpy array underneath the hood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46d6dfc-cf15-4c40-a45a-7944a60d3365",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e46410-f206-4515-ada8-d6e6f10a64a4",
   "metadata": {},
   "source": [
    "This means that the operations we saw for pandas Series can be applied to DataFrames as well, e.g. we can apply a scalar to every element in the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ec9c2e-1dc9-41fa-826e-b50fc41ed6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head() * 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91807d7-9558-404a-9086-5c4e493ffc26",
   "metadata": {},
   "source": [
    "However, the operation needs to be valid for ALL elements if we want to do this - e.g. while `*` is overridden for strings, `/` is not and will fail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48c1acb-dd3b-4854-bd81-34c950c52c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head() / 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206ae4be-db95-432f-82b9-99e0b4b331a0",
   "metadata": {},
   "source": [
    "Aggergation functions are by default done by column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2040ba8a-cc1b-47d8-b911-2681c2009dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87639f2-015c-43b1-8bd4-c83abbec2a91",
   "metadata": {},
   "source": [
    "However we can also make them aggregate by row:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f543418e-d585-4b47-8dba-c2620a8c88b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.mean(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff067f64-ff4a-49af-9694-f476fec7c1cb",
   "metadata": {},
   "source": [
    "## Mutating the Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf27ad1-12a5-4fe2-8134-5590ddfaded1",
   "metadata": {},
   "source": [
    "Like with other functionality, mutating DataFrames is very similar to mutating Series.  For example, setting one column to a single value is easy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1350780a-4c16-496d-846e-88c5db1dc9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mutations = df_base.set_index('ts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b91160-308f-46ab-9951-f9dd605c6edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mutations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2a4d5f-7e27-426e-a5d8-68a66f6fc2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mutations['chain'] = 'NA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b2f97a-f571-455a-b402-3adb40d14d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mutations.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d75c5a-490d-4301-bfd3-daec8420eab1",
   "metadata": {},
   "source": [
    "We can also create a new column and add data by index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d117c81-76f3-40e3-9de3-ea7d1412f1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "updates = pd.Series({pd.to_datetime('2021-12-01 00:00:00'): 1})\n",
    "updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e7e41f-a5c4-48ca-8636-635fe6697139",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mutations['start_of_week'] = updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd01358-d9d4-4321-9e34-e3b0f3564ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mutations.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7914bc83-a392-44a0-9d50-1da0c30699a8",
   "metadata": {},
   "source": [
    "We can also use the `.assign(...)` method to update columns, e.g.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103ca7ca-9eba-426b-a87e-a742892d9a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mutations.assign(\n",
    "    chain=np.where(df_mutations.token.isin(['ETH', 'AAVE', 'COMP']), np.full(df_mutations.shape[0], 'ETH'), df_mutations.token),\n",
    "    start_of_week=np.NaN\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e11d1ce-62ee-4604-b36c-806e2bcb9c7d",
   "metadata": {},
   "source": [
    "**note**: using the index notation `[*]` will mutate the dataframe in place, however `.assign` will return a new data frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8473769a-d6eb-427f-b044-3560e737998e",
   "metadata": {},
   "source": [
    "We can also rename columns using a `{from:to}` syntax, e.g.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1c0e14-64fe-42d1-9b9c-f99f6c486eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mutations.rename(\n",
    "    columns={\n",
    "        'open':'OpeningPrice',\n",
    "        'chain':'CryptoChain'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51d88eb-1552-4426-8665-df73c0be36f4",
   "metadata": {},
   "source": [
    "We can also use functions to rename, e.g.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37344475-6a0c-49df-a31e-047f3d73f613",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mutations.rename(columns=lambda x: x.upper())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b96baa5-12bf-474d-8491-08bb7d32ca4b",
   "metadata": {},
   "source": [
    "The above commands will return a new DataFrame.  If we want to rename the input DataFrame, we can use the `inplace` option (which is available on most mutating functions), such as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4408127b-73b7-4646-a6f9-9b7c26da570e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mutations.rename(\n",
    "    columns={\n",
    "        'open':'OpeningPrice',\n",
    "        'chain':'CryptoChain'\n",
    "    },\n",
    "    inplace=True\n",
    ")\n",
    "\n",
    "df_mutations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfcbccf7-c6d7-4ffe-a9d4-8f38ee1932a4",
   "metadata": {},
   "source": [
    "We can also add rows to the DataFrame by using `append`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47e4476-c228-438b-a7ad-f6e391e8f9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mutations.append(\n",
    "    pd.Series({\n",
    "        'high': 1,\n",
    "        'low': 2,\n",
    "        'token': 'FAKE'\n",
    "    }, name=pd.to_datetime('2021-11-30 00:00:00'))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1f9aee-5e0b-4f34-8114-59214d4bc5ea",
   "metadata": {},
   "source": [
    "## Sorting DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d922499d-88b1-405a-8d11-d19513f61eb7",
   "metadata": {},
   "source": [
    "One thing that we didn't need to really do with Series is sorting.  For DataFrames, we will often need to sort by column(s) or by the index.  We can use `sort_values` and `sort_index` to do this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14da04b-2cd7-461e-9adc-fd1f00ec101e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values('open')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cddb6e-f3d4-4a43-9778-dbdce374a6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values('open', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f22db1b-5c78-4325-99b0-0d1bb06e82d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(['volumeUSD', 'open'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5972e9a-fad5-4d49-b030-af5c186c23c1",
   "metadata": {},
   "source": [
    "We can also sort by the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44601df6-2b87-4fc9-b50b-2f6bb28bb3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20be5b51-a87a-4452-bd94-eeb06e720f9a",
   "metadata": {},
   "source": [
    "## Grouping DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ff739b-262e-4288-a049-ed2008d28ebc",
   "metadata": {},
   "source": [
    "one _very common_ action we will do during data manipulation is grouping then aggregating.  Pandas DataFrame has the method `groupby`, which allows us to group by any column in our DataFrame.\n",
    "\n",
    "`groupby` returns a `DataFrameGroupBy` object, which we can apply a function to each group, or directly aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb854a3-2ff4-4451-b915-e84441c8746e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('chain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44d4bab-ecc5-49c8-9826-8c6e4053eda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('chain').groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830c0d1a-b753-429f-8a9b-206c091cca71",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df.groupby('chain'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6089ac79-b7d1-42b1-8609-bb5fc9747e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('chain').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ab63cc-c697-4433-85bb-95c60ca47b6e",
   "metadata": {},
   "source": [
    "after grouping, we can operate on the whole DataFrame or on any column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a6383d-34c3-4866-87a6-ccca23e13b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('chain')['volumeUSD'].sum().to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13ef96e-5068-446c-bbb2-e3d9b33d6ff9",
   "metadata": {},
   "source": [
    "we can also groupby multiple columns.  The row indices now are a multi-index, however we will not go into this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100c9fc6-bc07-48c8-8577-40c7720f8f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['chain', 'token'])['volumeUSD'].sum().to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659d01d6-ea31-4390-b2b9-115f0757f19d",
   "metadata": {},
   "source": [
    "We can actually aggregate without setting a compound index by adding `as_index=False`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c27d74-9dd8-4882-84b3-524eba855628",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['chain', 'token'], as_index=False)['volumeUSD'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08c14d2-50b5-4953-b5ab-625ab79e7c2b",
   "metadata": {},
   "source": [
    "We can now operate on the groups.  For example, if we wanted to sum all columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f695e121-551c-439b-bfc6-db5771dfefce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('chain').aggregate(np.sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af35da5-b4ee-4389-82ea-4f1201d44c2c",
   "metadata": {},
   "source": [
    "or describe all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4704fa55-7da0-4d8b-9452-e3c647361fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('chain').describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec852e35-52c8-4537-9ea1-c75f1b617fd5",
   "metadata": {},
   "source": [
    "We can also do multiple aggregations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7df4c7-9970-4cdc-b9a7-d4743c230cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('chain')['open'].agg([np.size, np.mean, np.std, np.min, np.max])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee39879-6fcc-46df-bc23-3f1ac6b88709",
   "metadata": {},
   "source": [
    "we can actually use _any_ arbitrary functions - for example, we can use lambdas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbefbc4a-4ee9-4ccd-9445-f77555b02f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('chain')['open'].agg(\n",
    "    range=lambda x: x.max() - x.min()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3483fd-4414-48de-a5c2-079df13fc29a",
   "metadata": {},
   "source": [
    "## Joining Dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba09803-3569-4589-ac05-7b3f494f93c2",
   "metadata": {},
   "source": [
    "One of the primary things we need to do before starting to clean data is to make sure that we can get all of our data into one place.  This is usually called either a fat talbe or a long table, depending on how we are doing the joining.  We'll look at a few different ways to join pandas DataFrames below.\n",
    "\n",
    "We will be using `dfs`, which is a list of DataFrames that we created up above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ca9369-3e75-4d5a-8d48-2d086e07202d",
   "metadata": {},
   "source": [
    "### `pd.concat`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7573d60c-fa4b-4d71-8d82-d3ef4fea47ee",
   "metadata": {},
   "source": [
    "To join the dataframes lengthwise, we can use `pd.concat`.  This will append the dataframes together, and join the rows by using the column names as an index.  If any dataframe doesn't have a column name another one has, it will appear in the full DataFrame but will have NA for the missing DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b962217d-3fe4-45c6-b8d9-fb157aeafde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62fd591-0e09-4441-bc84-66b386cbc912",
   "metadata": {},
   "source": [
    "if you wanted to make sure you know where the original data is from, we can add keys, which creates a multi index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016428cf-5f57-473a-8c59-379252388fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.concat(dfs, keys=tokens)\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a41f290-b707-4a25-a06b-769a3bf2b1a6",
   "metadata": {},
   "source": [
    "this allows us to select the data from the source tables, e.g.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8cd015-564a-47ec-a627-9cb645854265",
   "metadata": {},
   "outputs": [],
   "source": [
    "res.loc['COMP']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916a0ca5-8be8-4f1b-be1d-34e3f7ab9661",
   "metadata": {},
   "source": [
    "As we saw above, we can also use `.append(*)` on DataFrames as well as Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2468f51-7655-488f-b91d-f1cb4aef1491",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[0].append(dfs[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a653bcc-af5a-4b8b-ad26-7fe08eb12152",
   "metadata": {},
   "source": [
    "Lastly, remember the importance of indices.  In the operation above (both `.concat` and `.append`) we joined the DataFrames while keeping the indices of the original tables.  This means that we have repeated indices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfbc556-fa49-4b49-9cb4-49eae932af41",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[0].append(dfs[1]).sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6397c0db-9dc8-4974-8957-e27cc121bb89",
   "metadata": {},
   "source": [
    "This sometimes isn't ideal, esp. if we want to join against these indices later.  Instead, we can create a new index on the joined table using the `ignore_index` parameter, which allows us to have a sequential, non-repeated index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d541867-a656-4b66-b002-de1d62d0b1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[0].append(dfs[1], ignore_index=True).sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99287e8d-e9bc-40a9-8cb5-f917f7782c1f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### `pd.DataFrame.join`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbcbf3e-014c-4c3f-a8a8-12f20dc32bba",
   "metadata": {},
   "source": [
    "`df.join` is a nice and easy method that allows us to join two dataframes by their index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17b8f11-a916-4ecb-9e4f-f241628c458a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[0].set_index('ts')['close'].rename(f'close_{tokens[0]}').to_frame().join(\n",
    "    dfs[1].set_index('ts')['close'].rename(f'close_{tokens[1]}').to_frame()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed37ee6-3c50-491e-8efc-f18d88ba9f9a",
   "metadata": {},
   "source": [
    "we can get a little more advanced by having a **left** unkeyed DataFrame joining against a **right** keyed DataFrame, e.g.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2655e5c-8a67-402a-b4dd-7222de6bc499",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[0][['ts', 'close']].join(\n",
    "    dfs[1].set_index('ts')['close'].rename(f'close_{tokens[1]}').to_frame(),\n",
    "    on='ts'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c0af8c-473c-423b-aace-eef1c40aca1e",
   "metadata": {},
   "source": [
    "### `pd.merge`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67aff9b9-76a9-4630-842f-3c64bde8822a",
   "metadata": {},
   "source": [
    "`pd.merge` is Pandas way of doing sql-like joins (e.g. left join, inner join, outer join etc).  There are a few quirks we'll see though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438ca657-da41-45ed-8686-ce6d2d05ab32",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(\n",
    "    dfs[0][['ts', 'close']].rename(columns={'close': f'close_{tokens[0]}'}),\n",
    "    dfs[1][['ts', 'close']].rename(columns={'close': f'close_{tokens[1]}'}),\n",
    "    on='ts',\n",
    "    how='inner'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d09b723-44b3-4dab-91ee-dae51507967c",
   "metadata": {},
   "source": [
    "we can use other conditions for `how`, e.g. 'left', 'right', 'outer', and 'cross'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94561edf-6458-40bc-9fab-ecba36369b73",
   "metadata": {},
   "source": [
    "if left and right DataFrames have columns with the same name, pandas will automatically resolve the delta by adding `_x` and `_y` suffixes to the conflicted columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4045d9c5-ef35-49dd-a93f-6821b9172a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(\n",
    "    dfs[0][['ts', 'close']],\n",
    "    dfs[1][['ts', 'close']],\n",
    "    on='ts',\n",
    "    how='inner'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3cc60e-8ccd-4b27-ab4f-243f36e30211",
   "metadata": {},
   "source": [
    "however, we can also define our own suffixes, e.g."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f8a6f9-9931-4df7-8025-2d4c0464d77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(\n",
    "    dfs[0][['ts', 'close']],\n",
    "    dfs[1][['ts', 'close']],\n",
    "    on='ts',\n",
    "    how='inner',\n",
    "    suffixes=[f'_{tokens[0]}', f'_{tokens[1]}']\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
