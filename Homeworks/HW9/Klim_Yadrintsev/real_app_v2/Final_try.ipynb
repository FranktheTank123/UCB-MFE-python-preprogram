{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "27283f2d-fb26-4174-81cd-962af98ccf12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import keras as K\n",
    "import keras.layers as Dense\n",
    "import keras.models as Sequential\n",
    "import keras.optimizers as Adam\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0a52719b-4839-4fe0-a80f-c22bccee5283",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_location = 'sqlite:///../data_v2/avocado.db'\n",
    "data = pd.read_sql('SELECT * FROM avocado', data_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "19510be7-b083-42c6-82c2-39c8ca8a15bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "            Date AveragePrice Total Volume     4046       4225   4770  \\\n0  0  2015-12-27         1.33     64236.62  1036.74   54454.85  48.16   \n1  1  2015-12-20         1.35     54876.98   674.28   44638.81  58.33   \n2  2  2015-12-13         0.93    118220.22    794.7  109149.67  130.5   \n3  3  2015-12-06         1.08     78992.15   1132.0   71976.41  72.58   \n4  4  2015-11-29         1.28      51039.6   941.48   43838.39  75.78   \n5  5  2015-11-22         1.26     55979.78  1184.27   48067.99  43.61   \n6  6  2015-11-15         0.99     83453.76  1368.92   73672.72  93.26   \n7  7  2015-11-08         0.98    109428.33   703.75  101815.36   80.0   \n8  8  2015-11-01         1.02     99811.42  1022.15   87315.57  85.34   \n9  9  2015-10-25         1.07     74338.76    842.4   64757.44  113.0   \n\n  Total Bags Small Bags Large Bags XLarge Bags          type  year  region  \n0    8696.87    8603.62      93.25         0.0  conventional  2015  Albany  \n1    9505.56    9408.07      97.49         0.0  conventional  2015  Albany  \n2    8145.35    8042.21     103.14         0.0  conventional  2015  Albany  \n3    5811.16     5677.4     133.76         0.0  conventional  2015  Albany  \n4    6183.95    5986.26     197.69         0.0  conventional  2015  Albany  \n5    6683.91    6556.47     127.44         0.0  conventional  2015  Albany  \n6    8318.86    8196.81     122.05         0.0  conventional  2015  Albany  \n7    6829.22    6266.85     562.37         0.0  conventional  2015  Albany  \n8   11388.36   11104.53     283.83         0.0  conventional  2015  Albany  \n9    8625.92    8061.47     564.45         0.0  conventional  2015  Albany  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>Date</th>\n      <th>AveragePrice</th>\n      <th>Total Volume</th>\n      <th>4046</th>\n      <th>4225</th>\n      <th>4770</th>\n      <th>Total Bags</th>\n      <th>Small Bags</th>\n      <th>Large Bags</th>\n      <th>XLarge Bags</th>\n      <th>type</th>\n      <th>year</th>\n      <th>region</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>2015-12-27</td>\n      <td>1.33</td>\n      <td>64236.62</td>\n      <td>1036.74</td>\n      <td>54454.85</td>\n      <td>48.16</td>\n      <td>8696.87</td>\n      <td>8603.62</td>\n      <td>93.25</td>\n      <td>0.0</td>\n      <td>conventional</td>\n      <td>2015</td>\n      <td>Albany</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2015-12-20</td>\n      <td>1.35</td>\n      <td>54876.98</td>\n      <td>674.28</td>\n      <td>44638.81</td>\n      <td>58.33</td>\n      <td>9505.56</td>\n      <td>9408.07</td>\n      <td>97.49</td>\n      <td>0.0</td>\n      <td>conventional</td>\n      <td>2015</td>\n      <td>Albany</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>2015-12-13</td>\n      <td>0.93</td>\n      <td>118220.22</td>\n      <td>794.7</td>\n      <td>109149.67</td>\n      <td>130.5</td>\n      <td>8145.35</td>\n      <td>8042.21</td>\n      <td>103.14</td>\n      <td>0.0</td>\n      <td>conventional</td>\n      <td>2015</td>\n      <td>Albany</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>2015-12-06</td>\n      <td>1.08</td>\n      <td>78992.15</td>\n      <td>1132.0</td>\n      <td>71976.41</td>\n      <td>72.58</td>\n      <td>5811.16</td>\n      <td>5677.4</td>\n      <td>133.76</td>\n      <td>0.0</td>\n      <td>conventional</td>\n      <td>2015</td>\n      <td>Albany</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>2015-11-29</td>\n      <td>1.28</td>\n      <td>51039.6</td>\n      <td>941.48</td>\n      <td>43838.39</td>\n      <td>75.78</td>\n      <td>6183.95</td>\n      <td>5986.26</td>\n      <td>197.69</td>\n      <td>0.0</td>\n      <td>conventional</td>\n      <td>2015</td>\n      <td>Albany</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>5</td>\n      <td>2015-11-22</td>\n      <td>1.26</td>\n      <td>55979.78</td>\n      <td>1184.27</td>\n      <td>48067.99</td>\n      <td>43.61</td>\n      <td>6683.91</td>\n      <td>6556.47</td>\n      <td>127.44</td>\n      <td>0.0</td>\n      <td>conventional</td>\n      <td>2015</td>\n      <td>Albany</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>6</td>\n      <td>2015-11-15</td>\n      <td>0.99</td>\n      <td>83453.76</td>\n      <td>1368.92</td>\n      <td>73672.72</td>\n      <td>93.26</td>\n      <td>8318.86</td>\n      <td>8196.81</td>\n      <td>122.05</td>\n      <td>0.0</td>\n      <td>conventional</td>\n      <td>2015</td>\n      <td>Albany</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>7</td>\n      <td>2015-11-08</td>\n      <td>0.98</td>\n      <td>109428.33</td>\n      <td>703.75</td>\n      <td>101815.36</td>\n      <td>80.0</td>\n      <td>6829.22</td>\n      <td>6266.85</td>\n      <td>562.37</td>\n      <td>0.0</td>\n      <td>conventional</td>\n      <td>2015</td>\n      <td>Albany</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>8</td>\n      <td>2015-11-01</td>\n      <td>1.02</td>\n      <td>99811.42</td>\n      <td>1022.15</td>\n      <td>87315.57</td>\n      <td>85.34</td>\n      <td>11388.36</td>\n      <td>11104.53</td>\n      <td>283.83</td>\n      <td>0.0</td>\n      <td>conventional</td>\n      <td>2015</td>\n      <td>Albany</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>9</td>\n      <td>2015-10-25</td>\n      <td>1.07</td>\n      <td>74338.76</td>\n      <td>842.4</td>\n      <td>64757.44</td>\n      <td>113.0</td>\n      <td>8625.92</td>\n      <td>8061.47</td>\n      <td>564.45</td>\n      <td>0.0</td>\n      <td>conventional</td>\n      <td>2015</td>\n      <td>Albany</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6774f3e1-2ba5-4412-8a69-ab3db4f2c80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.iloc[: , 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1100b57b-8dd7-41c5-a76f-0e700563763e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#seperating the prices to be predicted\n",
    "y = data.AveragePrice\n",
    "data.drop(['AveragePrice'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "74841686-0110-4811-8549-7991c79c062c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.astype({'Date': 'object', 'Total Volume' : 'float64', '4046' : 'float64', '4225' : 'float64', '4770' : 'float64', 'Total Bags' : 'float64', 'Small Bags' : 'float64', 'Large Bags' : 'float64', 'XLarge Bags' : 'float64', 'type' : 'object', 'year' : 'int', 'region':'object' })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "920ffe21-e3e1-4e0e-9b79-3d676f09f1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train-test split\n",
    "#splitting the data into training and test datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "trainflights, testflights, ytrain, ytest = train_test_split(data, y, train_size=0.7,test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1fb9d62d-91a6-44b9-8d95-98403829b923",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = (trainflights.dtypes == 'object')\n",
    "object_cols = list(s[s].index)\n",
    "\n",
    "n = (trainflights.dtypes == ('float64','int64'))\n",
    "numerical_cols = list(n[n].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Date', 'type', 'region']\n"
     ]
    }
   ],
   "source": [
    "#checking the columns containing categorical columns:\n",
    "print(object_cols)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "#using One Hot Encoder to make the categorical columns usable\n",
    "\n",
    "oneHot = OneHotEncoder(handle_unknown = 'ignore', sparse=False)\n",
    "oneHottrain = pd.DataFrame(oneHot.fit_transform(trainflights[object_cols]))\n",
    "oneHottest = pd.DataFrame(oneHot.transform(testflights[object_cols]))\n",
    "\n",
    "#reattaching index since OneHotEncoder removes them:\n",
    "oneHottrain.index = trainflights.index\n",
    "oneHottest.index = testflights.index\n",
    "\n",
    "#dropping the old categorical columns:\n",
    "cattraincol = trainflights.drop(object_cols, axis=1)\n",
    "cattestcol = testflights.drop(object_cols, axis=1)\n",
    "\n",
    "#concatenating the new columns:\n",
    "trainflights = pd.concat([cattraincol, oneHottrain], axis=1)\n",
    "testflights = pd.concat([cattestcol, oneHottest], axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "#scaling the values\n",
    "\n",
    "trainf = trainflights.values\n",
    "testf = testflights.values\n",
    "\n",
    "minmax = MinMaxScaler()\n",
    "\n",
    "trainflights = minmax.fit_transform(trainf)\n",
    "testflights = minmax.transform(testf)\n",
    "\n",
    "#defining a way to find Mean Absolute Percentage Error:\n",
    "def PercentError(preds, ytest):\n",
    "  error = abs(preds - ytest)\n",
    "\n",
    "  errorp = np.mean(100 - 100*(error/ytest))\n",
    "\n",
    "  print('the accuracy is:', errorp)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:   17.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": "RandomForestRegressor(random_state=0, verbose=1)"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#implementing the algo:\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=0, verbose=1)\n",
    "\n",
    "#fitting the data to random forest regressor:\n",
    "model.fit(trainflights, ytrain)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "#predicting the test dataset:\n",
    "preds = model.predict(testflights)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[6.90448956e-05, 6.28361995e-05, 8.48036854e-05, ...,\n        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n       [3.04983851e-03, 2.26192834e-04, 5.83556075e-03, ...,\n        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n       [1.67243653e-02, 4.85976831e-03, 1.72295234e-02, ...,\n        1.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n       ...,\n       [3.20848327e-03, 2.04921690e-03, 4.00552743e-03, ...,\n        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n       [4.39516087e-04, 8.12261011e-04, 4.59045293e-04, ...,\n        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n       [7.15962190e-03, 2.01183793e-04, 1.69275343e-02, ...,\n        0.00000000e+00, 0.00000000e+00, 0.00000000e+00]])"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testflights"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "ytest = ytest.astype('float')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the accuracy is: 92.16058342518666\n"
     ]
    }
   ],
   "source": [
    "PercentError(preds, ytest)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "datac = data\n",
    "datac = datac.set_index('Date')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data[data.Date == '2015-12-06']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "datac.loc['2015-12-06']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "         Date  Total Volume    4046      4225   4770  Total Bags  Small Bags  \\\n3  2015-12-06      78992.15  1132.0  71976.41  72.58     5811.16      5677.4   \n\n   Large Bags  XLarge Bags          type    year  region  \n3      133.76          0.0  conventional  2015.0  Albany  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>Total Volume</th>\n      <th>4046</th>\n      <th>4225</th>\n      <th>4770</th>\n      <th>Total Bags</th>\n      <th>Small Bags</th>\n      <th>Large Bags</th>\n      <th>XLarge Bags</th>\n      <th>type</th>\n      <th>year</th>\n      <th>region</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3</th>\n      <td>2015-12-06</td>\n      <td>78992.15</td>\n      <td>1132.0</td>\n      <td>71976.41</td>\n      <td>72.58</td>\n      <td>5811.16</td>\n      <td>5677.4</td>\n      <td>133.76</td>\n      <td>0.0</td>\n      <td>conventional</td>\n      <td>2015.0</td>\n      <td>Albany</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datacl = data[data['Date'] == '2015-12-06']\n",
    "datacll = datacl[datacl.region == 'Albany'].where(datacl.type == 'conventional').dropna()\n",
    "datacll\n",
    "# datacl.where(datac['region'] == 'Albany')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Date': {0: '2015-12-27', 1: '2015-12-20', 2: '2015-12-13', 3: '2015-12-06', 4: '2015-11-29'}, 'Total Volume': {0: 64236.62, 1: 54876.98, 2: 118220.22, 3: 78992.15, 4: 51039.6}, '4046': {0: 1036.74, 1: 674.28, 2: 794.7, 3: 1132.0, 4: 941.48}, '4225': {0: 54454.85, 1: 44638.81, 2: 109149.67, 3: 71976.41, 4: 43838.39}, '4770': {0: 48.16, 1: 58.33, 2: 130.5, 3: 72.58, 4: 75.78}, 'Total Bags': {0: 8696.87, 1: 9505.56, 2: 8145.35, 3: 5811.16, 4: 6183.95}, 'Small Bags': {0: 8603.62, 1: 9408.07, 2: 8042.21, 3: 5677.4, 4: 5986.26}, 'Large Bags': {0: 93.25, 1: 97.49, 2: 103.14, 3: 133.76, 4: 197.69}, 'XLarge Bags': {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, 'type': {0: 'conventional', 1: 'conventional', 2: 'conventional', 3: 'conventional', 4: 'conventional'}, 'year': {0: 2015, 1: 2015, 2: 2015, 3: 2015, 4: 2015}, 'region': {0: 'Albany', 1: 'Albany', 2: 'Albany', 3: 'Albany', 4: 'Albany'}}\n"
     ]
    }
   ],
   "source": [
    "print(data.head(5).to_dict())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "datetime.datetime(2015, 12, 6, 0, 0)"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "datetime.strptime('2015-12-06', '%Y-%m-%d')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "78992.15",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Input \u001B[0;32mIn [38]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mloc\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m78992.15\u001B[39;49m\u001B[43m]\u001B[49m\n",
      "File \u001B[0;32m/usr/local/bin/venv_python_main/lib/python3.9/site-packages/pandas/core/indexing.py:967\u001B[0m, in \u001B[0;36m_LocationIndexer.__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m    964\u001B[0m axis \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maxis \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m    966\u001B[0m maybe_callable \u001B[38;5;241m=\u001B[39m com\u001B[38;5;241m.\u001B[39mapply_if_callable(key, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobj)\n\u001B[0;32m--> 967\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_getitem_axis\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmaybe_callable\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maxis\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/local/bin/venv_python_main/lib/python3.9/site-packages/pandas/core/indexing.py:1202\u001B[0m, in \u001B[0;36m_LocIndexer._getitem_axis\u001B[0;34m(self, key, axis)\u001B[0m\n\u001B[1;32m   1200\u001B[0m \u001B[38;5;66;03m# fall thru to straight lookup\u001B[39;00m\n\u001B[1;32m   1201\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_key(key, axis)\n\u001B[0;32m-> 1202\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_label\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maxis\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/local/bin/venv_python_main/lib/python3.9/site-packages/pandas/core/indexing.py:1153\u001B[0m, in \u001B[0;36m_LocIndexer._get_label\u001B[0;34m(self, label, axis)\u001B[0m\n\u001B[1;32m   1151\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_get_label\u001B[39m(\u001B[38;5;28mself\u001B[39m, label, axis: \u001B[38;5;28mint\u001B[39m):\n\u001B[1;32m   1152\u001B[0m     \u001B[38;5;66;03m# GH#5667 this will fail if the label is not present in the axis.\u001B[39;00m\n\u001B[0;32m-> 1153\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mobj\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mxs\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlabel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maxis\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/local/bin/venv_python_main/lib/python3.9/site-packages/pandas/core/generic.py:3876\u001B[0m, in \u001B[0;36mNDFrame.xs\u001B[0;34m(self, key, axis, level, drop_level)\u001B[0m\n\u001B[1;32m   3874\u001B[0m             new_index \u001B[38;5;241m=\u001B[39m index[loc]\n\u001B[1;32m   3875\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 3876\u001B[0m     loc \u001B[38;5;241m=\u001B[39m \u001B[43mindex\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3878\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(loc, np\u001B[38;5;241m.\u001B[39mndarray):\n\u001B[1;32m   3879\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m loc\u001B[38;5;241m.\u001B[39mdtype \u001B[38;5;241m==\u001B[39m np\u001B[38;5;241m.\u001B[39mbool_:\n",
      "File \u001B[0;32m/usr/local/bin/venv_python_main/lib/python3.9/site-packages/pandas/core/indexes/range.py:389\u001B[0m, in \u001B[0;36mRangeIndex.get_loc\u001B[0;34m(self, key, method, tolerance)\u001B[0m\n\u001B[1;32m    387\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n\u001B[1;32m    388\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_indexing_error(key)\n\u001B[0;32m--> 389\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key)\n\u001B[1;32m    390\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39mget_loc(key, method\u001B[38;5;241m=\u001B[39mmethod, tolerance\u001B[38;5;241m=\u001B[39mtolerance)\n",
      "\u001B[0;31mKeyError\u001B[0m: 78992.15"
     ]
    }
   ],
   "source": [
    "data.loc[78992.15]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "LinearRegression()"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using linear regression:\n",
    "LinearModel = LinearRegression()\n",
    "LinearModel.fit(trainflights, ytrain)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "95200552-88d2-44c9-a51e-0b2596bd323a",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'float' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "File \u001B[0;32m/usr/local/bin/venv_python_main/lib/python3.9/site-packages/pandas/core/ops/array_ops.py:163\u001B[0m, in \u001B[0;36m_na_arithmetic_op\u001B[0;34m(left, right, op, is_cmp)\u001B[0m\n\u001B[1;32m    162\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 163\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mleft\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mright\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    164\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n",
      "File \u001B[0;32m/usr/local/bin/venv_python_main/lib/python3.9/site-packages/pandas/core/computation/expressions.py:239\u001B[0m, in \u001B[0;36mevaluate\u001B[0;34m(op, a, b, use_numexpr)\u001B[0m\n\u001B[1;32m    237\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m use_numexpr:\n\u001B[1;32m    238\u001B[0m         \u001B[38;5;66;03m# error: \"None\" not callable\u001B[39;00m\n\u001B[0;32m--> 239\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_evaluate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mop\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_str\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43ma\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mb\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m    240\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m _evaluate_standard(op, op_str, a, b)\n",
      "File \u001B[0;32m/usr/local/bin/venv_python_main/lib/python3.9/site-packages/pandas/core/computation/expressions.py:69\u001B[0m, in \u001B[0;36m_evaluate_standard\u001B[0;34m(op, op_str, a, b)\u001B[0m\n\u001B[1;32m     68\u001B[0m     _store_test_result(\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m---> 69\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mop\u001B[49m\u001B[43m(\u001B[49m\u001B[43ma\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mb\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/local/bin/venv_python_main/lib/python3.9/site-packages/pandas/core/roperator.py:13\u001B[0m, in \u001B[0;36mrsub\u001B[0;34m(left, right)\u001B[0m\n\u001B[1;32m     12\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrsub\u001B[39m(left, right):\n\u001B[0;32m---> 13\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mright\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mleft\u001B[49m\n",
      "\u001B[0;31mTypeError\u001B[0m: unsupported operand type(s) for -: 'float' and 'str'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [40]\u001B[0m, in \u001B[0;36m<cell line: 3>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m#predicting on the test dataset:\u001B[39;00m\n\u001B[1;32m      2\u001B[0m LinearPredictions \u001B[38;5;241m=\u001B[39m LinearModel\u001B[38;5;241m.\u001B[39mpredict(testflights)\n\u001B[0;32m----> 3\u001B[0m \u001B[43mPercentError\u001B[49m\u001B[43m(\u001B[49m\u001B[43mLinearPredictions\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mytest\u001B[49m\u001B[43m)\u001B[49m\n",
      "Input \u001B[0;32mIn [34]\u001B[0m, in \u001B[0;36mPercentError\u001B[0;34m(preds, ytest)\u001B[0m\n\u001B[1;32m     12\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mPercentError\u001B[39m(preds, ytest):\n\u001B[0;32m---> 13\u001B[0m   error \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mabs\u001B[39m(\u001B[43mpreds\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mytest\u001B[49m)\n\u001B[1;32m     15\u001B[0m   errorp \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mmean(\u001B[38;5;241m100\u001B[39m \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m100\u001B[39m\u001B[38;5;241m*\u001B[39m(error\u001B[38;5;241m/\u001B[39mytest))\n\u001B[1;32m     17\u001B[0m   \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mthe accuracy is:\u001B[39m\u001B[38;5;124m'\u001B[39m, errorp)\n",
      "File \u001B[0;32m/usr/local/bin/venv_python_main/lib/python3.9/site-packages/pandas/core/generic.py:2113\u001B[0m, in \u001B[0;36mNDFrame.__array_ufunc__\u001B[0;34m(self, ufunc, method, *inputs, **kwargs)\u001B[0m\n\u001B[1;32m   2109\u001B[0m \u001B[38;5;129m@final\u001B[39m\n\u001B[1;32m   2110\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__array_ufunc__\u001B[39m(\n\u001B[1;32m   2111\u001B[0m     \u001B[38;5;28mself\u001B[39m, ufunc: np\u001B[38;5;241m.\u001B[39mufunc, method: \u001B[38;5;28mstr\u001B[39m, \u001B[38;5;241m*\u001B[39minputs: Any, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any\n\u001B[1;32m   2112\u001B[0m ):\n\u001B[0;32m-> 2113\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43marraylike\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43marray_ufunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mufunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/local/bin/venv_python_main/lib/python3.9/site-packages/pandas/core/arraylike.py:263\u001B[0m, in \u001B[0;36marray_ufunc\u001B[0;34m(self, ufunc, method, *inputs, **kwargs)\u001B[0m\n\u001B[1;32m    260\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m result\n\u001B[1;32m    262\u001B[0m \u001B[38;5;66;03m# for binary ops, use our custom dunder methods\u001B[39;00m\n\u001B[0;32m--> 263\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[43mmaybe_dispatch_ufunc_to_dunder_op\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mufunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    264\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m result \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mNotImplemented\u001B[39m:\n\u001B[1;32m    265\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[0;32m/usr/local/bin/venv_python_main/lib/python3.9/site-packages/pandas/_libs/ops_dispatch.pyx:113\u001B[0m, in \u001B[0;36mpandas._libs.ops_dispatch.maybe_dispatch_ufunc_to_dunder_op\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m/usr/local/bin/venv_python_main/lib/python3.9/site-packages/pandas/core/ops/common.py:70\u001B[0m, in \u001B[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001B[0;34m(self, other)\u001B[0m\n\u001B[1;32m     66\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mNotImplemented\u001B[39m\n\u001B[1;32m     68\u001B[0m other \u001B[38;5;241m=\u001B[39m item_from_zerodim(other)\n\u001B[0;32m---> 70\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mmethod\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mother\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/local/bin/venv_python_main/lib/python3.9/site-packages/pandas/core/arraylike.py:112\u001B[0m, in \u001B[0;36mOpsMixin.__rsub__\u001B[0;34m(self, other)\u001B[0m\n\u001B[1;32m    110\u001B[0m \u001B[38;5;129m@unpack_zerodim_and_defer\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__rsub__\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    111\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__rsub__\u001B[39m(\u001B[38;5;28mself\u001B[39m, other):\n\u001B[0;32m--> 112\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_arith_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43mother\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mroperator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrsub\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/local/bin/venv_python_main/lib/python3.9/site-packages/pandas/core/series.py:5639\u001B[0m, in \u001B[0;36mSeries._arith_method\u001B[0;34m(self, other, op)\u001B[0m\n\u001B[1;32m   5637\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_arith_method\u001B[39m(\u001B[38;5;28mself\u001B[39m, other, op):\n\u001B[1;32m   5638\u001B[0m     \u001B[38;5;28mself\u001B[39m, other \u001B[38;5;241m=\u001B[39m ops\u001B[38;5;241m.\u001B[39malign_method_SERIES(\u001B[38;5;28mself\u001B[39m, other)\n\u001B[0;32m-> 5639\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mbase\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mIndexOpsMixin\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_arith_method\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mother\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/local/bin/venv_python_main/lib/python3.9/site-packages/pandas/core/base.py:1295\u001B[0m, in \u001B[0;36mIndexOpsMixin._arith_method\u001B[0;34m(self, other, op)\u001B[0m\n\u001B[1;32m   1292\u001B[0m rvalues \u001B[38;5;241m=\u001B[39m ensure_wrapped_if_datetimelike(rvalues)\n\u001B[1;32m   1294\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m np\u001B[38;5;241m.\u001B[39merrstate(\u001B[38;5;28mall\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mignore\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m-> 1295\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43marithmetic_op\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1297\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_construct_result(result, name\u001B[38;5;241m=\u001B[39mres_name)\n",
      "File \u001B[0;32m/usr/local/bin/venv_python_main/lib/python3.9/site-packages/pandas/core/ops/array_ops.py:222\u001B[0m, in \u001B[0;36marithmetic_op\u001B[0;34m(left, right, op)\u001B[0m\n\u001B[1;32m    217\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    218\u001B[0m     \u001B[38;5;66;03m# TODO we should handle EAs consistently and move this check before the if/else\u001B[39;00m\n\u001B[1;32m    219\u001B[0m     \u001B[38;5;66;03m# (https://github.com/pandas-dev/pandas/issues/41165)\u001B[39;00m\n\u001B[1;32m    220\u001B[0m     _bool_arith_check(op, left, right)\n\u001B[0;32m--> 222\u001B[0m     res_values \u001B[38;5;241m=\u001B[39m \u001B[43m_na_arithmetic_op\u001B[49m\u001B[43m(\u001B[49m\u001B[43mleft\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mright\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    224\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m res_values\n",
      "File \u001B[0;32m/usr/local/bin/venv_python_main/lib/python3.9/site-packages/pandas/core/ops/array_ops.py:170\u001B[0m, in \u001B[0;36m_na_arithmetic_op\u001B[0;34m(left, right, op, is_cmp)\u001B[0m\n\u001B[1;32m    164\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[1;32m    165\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_cmp \u001B[38;5;129;01mand\u001B[39;00m (is_object_dtype(left\u001B[38;5;241m.\u001B[39mdtype) \u001B[38;5;129;01mor\u001B[39;00m is_object_dtype(right)):\n\u001B[1;32m    166\u001B[0m         \u001B[38;5;66;03m# For object dtype, fallback to a masked operation (only operating\u001B[39;00m\n\u001B[1;32m    167\u001B[0m         \u001B[38;5;66;03m#  on the non-missing values)\u001B[39;00m\n\u001B[1;32m    168\u001B[0m         \u001B[38;5;66;03m# Don't do this for comparisons, as that will handle complex numbers\u001B[39;00m\n\u001B[1;32m    169\u001B[0m         \u001B[38;5;66;03m#  incorrectly, see GH#32047\u001B[39;00m\n\u001B[0;32m--> 170\u001B[0m         result \u001B[38;5;241m=\u001B[39m \u001B[43m_masked_arith_op\u001B[49m\u001B[43m(\u001B[49m\u001B[43mleft\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mright\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    171\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    172\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m\n",
      "File \u001B[0;32m/usr/local/bin/venv_python_main/lib/python3.9/site-packages/pandas/core/ops/array_ops.py:108\u001B[0m, in \u001B[0;36m_masked_arith_op\u001B[0;34m(x, y, op)\u001B[0m\n\u001B[1;32m    106\u001B[0m     \u001B[38;5;66;03m# See GH#5284, GH#5035, GH#19448 for historical reference\u001B[39;00m\n\u001B[1;32m    107\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m mask\u001B[38;5;241m.\u001B[39many():\n\u001B[0;32m--> 108\u001B[0m         result[mask] \u001B[38;5;241m=\u001B[39m \u001B[43mop\u001B[49m\u001B[43m(\u001B[49m\u001B[43mxrav\u001B[49m\u001B[43m[\u001B[49m\u001B[43mmask\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43myrav\u001B[49m\u001B[43m[\u001B[49m\u001B[43mmask\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    110\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    111\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_scalar(y):\n",
      "File \u001B[0;32m/usr/local/bin/venv_python_main/lib/python3.9/site-packages/pandas/core/roperator.py:13\u001B[0m, in \u001B[0;36mrsub\u001B[0;34m(left, right)\u001B[0m\n\u001B[1;32m     12\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrsub\u001B[39m(left, right):\n\u001B[0;32m---> 13\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mright\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mleft\u001B[49m\n",
      "\u001B[0;31mTypeError\u001B[0m: unsupported operand type(s) for -: 'float' and 'str'"
     ]
    }
   ],
   "source": [
    "#predicting on the test dataset:\n",
    "LinearPredictions = LinearModel.predict(testflights)\n",
    "PercentError(LinearPredictions, ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2e8716-66b7-43eb-999a-3a31f58c2939",
   "metadata": {},
   "source": [
    "I got to this point but I think that train_test_split is not allowed to be used on time series data. I am pretty sure that this is not time series data but it is very similar region wise I guess. Let's just assume that data is not time correlated in any way."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2cdfd9d-9b78-45a7-8dc6-1cf2876e8d2b",
   "metadata": {},
   "source": [
    "On the other hand how can it not be correlated? As we know what the price will be in August and in December, predicting the price in the October is much easier that way, that is why maybe just going for the train test split scews the correctness of the predictions by a long shot. What if I use TimeSeriesSplit instead?TimeSeriesSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3b5812-e912-4ff2-8799-10698f53893b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# pickle.dump(model, open('../data_v2/model.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5b4b5b-c96f-44f1-b5e8-0f6e4e867a74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}