{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2470b7b-3b15-47a1-af04-1e110fdc828d",
   "metadata": {},
   "source": [
    "# Assignment 8: Solana Returns Prediction Model / Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8adaafda-69cc-4893-8c34-28c1bad556ee",
   "metadata": {},
   "source": [
    "## The aim of the model is to optimize Solana Returns Model:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba65b349-d2f1-46e6-8d61-085ff17cc32b",
   "metadata": {},
   "source": [
    "### Import Initial Packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacb94a3-a314-4e31-80b6-fced535e87f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import reduce\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4f5b2e-e675-4598-b1fb-4f5f79305b59",
   "metadata": {},
   "source": [
    "### Volatility Calc.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc5909e-d47d-4184-8f50-886c6bdc7d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vol_ohlc(df, lookback=10):\n",
    "    o = df.open\n",
    "    h = df.high\n",
    "    l = df.low\n",
    "    c = df.close\n",
    "    \n",
    "    k = 0.34 / (1.34 + (lookback+1)/(lookback-1))\n",
    "    cc = np.log(c/c.shift(1))\n",
    "    ho = np.log(h/o)\n",
    "    lo = np.log(l/o)\n",
    "    co = np.log(c/o)\n",
    "    oc = np.log(o/c.shift(1))\n",
    "    oc_sq = oc**2\n",
    "    cc_sq = cc**2\n",
    "    rs = ho*(ho-co)+lo*(lo-co)\n",
    "    close_vol = cc_sq.rolling(lookback).sum() * (1.0 / (lookback - 1.0))\n",
    "    open_vol = oc_sq.rolling(lookback).sum() * (1.0 / (lookback - 1.0))\n",
    "    window_rs = rs.rolling(lookback).sum() * (1.0 / (lookback - 1.0))\n",
    "    result = (open_vol + k * close_vol + (1-k) * window_rs).apply(np.sqrt) * np.sqrt(252)\n",
    "    result[:lookback-1] = np.nan\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15c70fa-9a64-4ae3-8021-9627b734353e",
   "metadata": {},
   "source": [
    "### Setting the Learning Curve:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a33e4da-c2ab-4a21-97b7-98375bb4a9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(\n",
    "    estimator,\n",
    "    title,\n",
    "    X,\n",
    "    y,\n",
    "    axes=None,\n",
    "    ylim=None,\n",
    "    cv=None,\n",
    "    n_jobs=None,\n",
    "    train_sizes=np.linspace(0.1, 1.0, 5),\n",
    "    scoring=None\n",
    "):\n",
    "    if axes is None:\n",
    "        _, axes = plt.subplots(1, 3, figsize=(20, 5))\n",
    "\n",
    "    axes[0].set_title(title)\n",
    "    if ylim is not None:\n",
    "        axes[0].set_ylim(*ylim)\n",
    "    axes[0].set_xlabel(\"Training examples\")\n",
    "    axes[0].set_ylabel(\"Score\")\n",
    "\n",
    "    train_sizes, train_scores, test_scores, fit_times, _ = learning_curve(\n",
    "        estimator,\n",
    "        X,\n",
    "        y,\n",
    "        cv=cv,\n",
    "        n_jobs=n_jobs,\n",
    "        train_sizes=train_sizes,\n",
    "        return_times=True,\n",
    "        scoring=scoring,\n",
    "    )\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    fit_times_mean = np.mean(fit_times, axis=1)\n",
    "    fit_times_std = np.std(fit_times, axis=1)\n",
    "\n",
    "    # Plot learning curve\n",
    "    axes[0].grid()\n",
    "    axes[0].fill_between(\n",
    "        train_sizes,\n",
    "        train_scores_mean - train_scores_std,\n",
    "        train_scores_mean + train_scores_std,\n",
    "        alpha=0.1,\n",
    "        color=\"r\",\n",
    "    )\n",
    "    axes[0].fill_between(\n",
    "        train_sizes,\n",
    "        test_scores_mean - test_scores_std,\n",
    "        test_scores_mean + test_scores_std,\n",
    "        alpha=0.1,\n",
    "        color=\"g\",\n",
    "    )\n",
    "    axes[0].plot(\n",
    "        train_sizes, train_scores_mean, \"o-\", color=\"r\", label=\"Training score\"\n",
    "    )\n",
    "    axes[0].plot(\n",
    "        train_sizes, test_scores_mean, \"o-\", color=\"g\", label=\"Cross-validation score\"\n",
    "    )\n",
    "    axes[0].legend(loc=\"best\")\n",
    "\n",
    "    # Plot n_samples vs fit_times\n",
    "    axes[1].grid()\n",
    "    axes[1].plot(train_sizes, fit_times_mean, \"o-\")\n",
    "    axes[1].fill_between(\n",
    "        train_sizes,\n",
    "        fit_times_mean - fit_times_std,\n",
    "        fit_times_mean + fit_times_std,\n",
    "        alpha=0.1,\n",
    "    )\n",
    "    axes[1].set_xlabel(\"Training examples\")\n",
    "    axes[1].set_ylabel(\"fit_times\")\n",
    "    axes[1].set_title(\"Scalability of the model\")\n",
    "\n",
    "    # Plot fit_time vs score\n",
    "    fit_time_argsort = fit_times_mean.argsort()\n",
    "    fit_time_sorted = fit_times_mean[fit_time_argsort]\n",
    "    test_scores_mean_sorted = test_scores_mean[fit_time_argsort]\n",
    "    test_scores_std_sorted = test_scores_std[fit_time_argsort]\n",
    "    axes[2].grid()\n",
    "    axes[2].plot(fit_time_sorted, test_scores_mean_sorted, \"o-\")\n",
    "    axes[2].fill_between(\n",
    "        fit_time_sorted,\n",
    "        test_scores_mean_sorted - test_scores_std_sorted,\n",
    "        test_scores_mean_sorted + test_scores_std_sorted,\n",
    "        alpha=0.1,\n",
    "    )\n",
    "    axes[2].set_xlabel(\"fit_times\")\n",
    "    axes[2].set_ylabel(\"Score\")\n",
    "    axes[2].set_title(\"Performance of the model\")\n",
    "\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184a4377-f36c-4687-99bf-2ad540082b5b",
   "metadata": {},
   "source": [
    "### Extracting Our Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3ed3c6-01c4-4072-9a02-202e875f08d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_string = 'sqlite:///data/data.db'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af3258f-3e5c-4a5a-90c9-45ddda0ff138",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohlc = pd.read_sql('SELECT * FROM ohlc' , connection_string)\n",
    "ohlc['ts'] = pd.to_datetime(ohlc['ts'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480744a9-8211-4ccf-a1d6-781b4b18e3fd",
   "metadata": {},
   "source": [
    "### Understanding Our Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee40b52-6a75-4390-90b3-1c402222be13",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohlc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11acd696-24c0-42ad-aee3-ce2e37f18d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohlc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d9a974-789a-44b0-bd90-ae6ee3d70b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohlc.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13f7a16-4c8c-48a4-a889-4d34a98bff75",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohlc.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49d1665-accd-4afd-b165-7ee332aed376",
   "metadata": {},
   "source": [
    "### Preprocessing and Data Engineering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e064ef-6e1c-45a1-b7ac-7f6c6d430af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = ohlc.token.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2666ed-c3a1-4dcd-8bd7-7033e7e53706",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a38da5-4eb8-4993-9aff-a9b95a4766f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_low = ohlc['high'] - ohlc['low']\n",
    "high_cp = np.abs(ohlc['high'] - ohlc['close'].shift())\n",
    "low_cp = np.abs(ohlc['low'] - ohlc['close'].shift())\n",
    "\n",
    "df = pd.concat([high_low, high_cp, low_cp], axis=1)\n",
    "true_range = np.max(ohlc, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58be3882-bc9e-4c67-8d38-34f55f189efe",
   "metadata": {},
   "source": [
    "#### Additing Features:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7227a3db-6411-4111-8f3c-a8b3ea1e64cb",
   "metadata": {},
   "source": [
    "* I added 4 additional features to enrich our model:<br>\n",
    "1- Return close for period = 2, this will enrich the trend and understanding about returns.<br>\n",
    "2- Volume price trend to identify the parity between the supply and demand of a crypto coin.<br>\n",
    "3- USD_Volume return, this will enrich the trend and understanding about USD_volume returns.<br>\n",
    "4- Average True Range shows how much a crypto coin moves, on average, during a given time frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e23530-c93c-4329-bd94-d5929f613780",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_merge(left, right):\n",
    "    return pd.merge(left, right, on='ts', how='inner')\n",
    "\n",
    "X = reduce(df_merge, [\n",
    "    (lambda df: \n",
    "    (\n",
    "        df\n",
    "        .assign(\n",
    "            vol=vol_ohlc(df).fillna(0),\n",
    "            ret=df.close.pct_change(),\n",
    "            ret_period_2 = df.close.pct_change(2).fillna(0),\n",
    "            volume_price_trend = (df.close.pct_change()*df.volume).fillna(0),\n",
    "            USD_vol_ret = df.volumeUSD.pct_change().fillna(0),\n",
    "            average_true_range = true_range.rolling(14).mean().fillna(0)\n",
    "        )[['ts', 'vol', 'ret', 'ret_period_2', 'volume_price_trend', 'USD_vol_ret', 'average_true_range']]\n",
    "        .rename(columns={\n",
    "            col: f'{col}_{token}' for col in ['ts', 'vol', 'ret', 'ret_period_2', 'volume_price_trend', 'USD_vol_ret', 'average_true_range'] if col != 'ts'\n",
    "        })\n",
    "    ))(ohlc[ohlc.token == token])\n",
    "    for token in tokens\n",
    "]).set_index('ts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6cdc73-0d85-4580-b0eb-e5743184ab42",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433f36a7-4a62-49d8-bd64-ac933c0274c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = X.ret_SOL.shift(-1)[:-1]\n",
    "X = X[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6472a9b4-9203-41c8-b6f6-151fd234ba08",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2533488-6869-4c6c-ac21-8a1796f6d744",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4500582e-20e5-4140-bc23-d6402fbac61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5dd450-41ce-4e45-8c74-ed6d53bb41a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import scatter_matrix, autocorrelation_plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df76986-ed10-4034-8169-37c98fec6e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "autocorrelation_plot(y[1:])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e05da1-c763-4519-8f12-83088c9556be",
   "metadata": {},
   "source": [
    "* No strong correlation for Solana."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e906ca82-809a-4cbd-9a30-e31eb371f830",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.isnull(X).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30dcf9a-94a3-48ef-8efb-90f8bd99f8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "{col: y.corr(X[col]) for col in X.columns if X[col].dtype != 'object'}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036bb82e-81b8-4a10-9018-11618407c1fa",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Setting up our transformer and creating our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4317cb9c-e239-4be0-b93c-13e62c102e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "\n",
    "from sklearn.model_selection import learning_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8760c69d-6f02-4eb8-9d81-783f3b05f20c",
   "metadata": {},
   "source": [
    "#### Custom Transformer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d4c186-ffb1-4705-95bd-f11b311b8bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return X[self.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c510ab59-39a3-4f0c-8d1d-8c946231c2da",
   "metadata": {},
   "source": [
    "#### Model Construction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab10bf0c-91b0-42b7-b712-7358f1abd53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X, y, test_size=0.2):\n",
    "    cv = TimeSeriesSplit(n_splits=int(y.shape[0] * test_size), test_size=1)\n",
    "    scorer = make_scorer(mean_squared_error, greater_is_better=False, squared=False)\n",
    "    \n",
    "    return np.mean(cross_validate(model, X, y, cv=cv, scoring=scorer, n_jobs=-1)['test_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77db76b8-be7b-44c1-a885-69d7ceee8c3a",
   "metadata": {},
   "source": [
    "#### Model pipeline:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7a506a-2d49-47b1-ac91-0f6bf8cdfcd1",
   "metadata": {},
   "source": [
    "##### With Simple Ridge:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3059b79e-d73b-4f9a-887e-0f937fb4c46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('impute', SimpleImputer(missing_values=np.nan, strategy='constant', fill_value=0.)),\n",
    "    ('model', Ridge(alpha=0.1))\n",
    "])\n",
    "\n",
    "evaluate_model(pipeline, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b581bc-cad7-47e4-9050-b800f16cd85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 1, figsize=(10, 15))\n",
    "\n",
    "title = \"Learning curves for ridge regression\"\n",
    "\n",
    "plot_learning_curve(\n",
    "    pipeline, title, X, y, axes=axes, cv=cv, n_jobs=4, scoring=scorer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a5bd06-657f-495f-bdc1-1a0aaea41370",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### With RFR:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d914c32d-eccb-44ab-8af4-bf079d03e82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It will take time to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252a2b0b-0408-4dbc-b2b5-c4d2e3c55b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('impute', SimpleImputer(missing_values=np.nan, strategy='constant', fill_value=0.)),\n",
    "    ('model', RandomForestRegressor(n_estimators=100, random_state=0))\n",
    "])\n",
    "\n",
    "evaluate_model(pipeline, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9381458-7969-4fcd-a861-98b4dacd3fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('impute', SimpleImputer(missing_values=np.nan, strategy='constant', fill_value=0.)),\n",
    "    ('scale', StandardScaler()),\n",
    "    ('pca', PCA()),\n",
    "    ('model', Ridge())\n",
    "])\n",
    "\n",
    "test_size = 0.2\n",
    "cv = TimeSeriesSplit(n_splits=int(y.shape[0] * test_size), test_size=1)\n",
    "scorer = make_scorer(mean_squared_error, greater_is_better=False, squared=False)\n",
    "\n",
    "search = GridSearchCV(pipeline, {\n",
    "    'pca__n_components': [5, 10, 20, 40, 66],\n",
    "    'model__alpha' : [0.1, 0.5]\n",
    "}, scoring=scorer, refit=True, cv=cv, n_jobs=-1)\n",
    "search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3be298-731b-41a1-88f8-a1b5f39ece69",
   "metadata": {},
   "outputs": [],
   "source": [
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33c7544-bf8a-44fa-8888-d42b4a93c478",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = search.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b898bd1-b5a0-4c02-b7c0-95ba04234350",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(best_model, X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38108b93-f3fc-4411-8cd4-f28aeba09be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 1, figsize=(10, 15))\n",
    "\n",
    "title = \"Learning curves for ridge regression\"\n",
    "\n",
    "plot_learning_curve(\n",
    "    best_model, title, X, y, axes=axes, cv=cv, n_jobs=4, scoring=scorer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98193c06-1901-4c3f-8bdc-c16e4667972d",
   "metadata": {},
   "source": [
    "* We were able to beat the class average cross-validated RMSE which was -0.008575141851714435.\n",
    "\n",
    "  The above optimized model gives an average cross-validated RMSE of -0.00841268350558673."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac25473-89b7-461a-abed-c784046c7812",
   "metadata": {},
   "source": [
    "* However, it is worth mentioning that we are better off committing to the first model (Cell 26) rather than tuning Ridge hyperparameters. In the tuned model, it has lower average cross-validated RMSE but its learning curve is worse than that of the first model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e7b9b6-d2ba-4d6b-bcb7-286b25918b6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
